# -*- coding: utf-8 -*-
"""program2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gi1Fevi6gG2feWjdiHw5JKvP-oEPvgQ8
"""

from __future__ import print_function
import keras
from keras.models import Sequential
from keras.layers import Dense
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from keras.callbacks import TensorBoard
from time import time


dataset = pd.read_csv('heart.csv',index_col=0)
dataset.astype(float)

# Normalize values to range [0:1]
dataset /= dataset.max()

y = dataset['target']
X = dataset.drop(['target'], axis = 1)

X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.33, random_state = 0)

np.random.seed(155)
model = Sequential() # create model
model.add(Dense(40, input_dim=12, activation='relu')) # hidden layer
model.add(Dense(20, input_dim=40, activation='relu'))
model.add(Dense(1, activation='sigmoid')) # output layer

model.compile(loss= keras.losses.binary_crossentropy,
                  optimizer=keras.optimizers.adamax(),
                  metrics=['accuracy'])

tensorborad = TensorBoard(log_dir="logs/{}".format(time()))
history = model.fit(X_train, Y_train,batch_size=500,epochs=40,verbose=1,
           validation_data=(X_test, Y_test), callbacks=[tensorborad])

y_pred = model.predict_classes(X_test)

score = model.evaluate(X_test, Y_test, verbose=0)
print('Loss:', score[0])
print('Accuracy:', score[1])


def plot_hist(h, xsize=6, ysize=10):
    # Prepare plotting
    fig_size = plt.rcParams["figure.figsize"]
    plt.rcParams["figure.figsize"] = [xsize, ysize]
    fig, axes = plt.subplots(nrows=4, ncols=4, sharex=True)
    plt.subplot(212)
    plt.plot(h['loss'])
    plt.plot(h['val_loss'])
    plt.title('Training vs Validation Loss')
    plt.ylabel('Loss')
    plt.xlabel('Accuracy')
    plt.legend(['Train', 'Validation'], loc='upper left')

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs/

from __future__ import print_function
import keras
from keras.models import Sequential
from keras.layers import Dense
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from keras.callbacks import TensorBoard
from time import time


dataset = pd.read_csv('heart.csv',index_col=0)
dataset.astype(float)

# Normalize values to range [0:1]
dataset /= dataset.max()

y = dataset['target']
X = dataset.drop(['target'], axis = 1)

X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.33, random_state = 0)

np.random.seed(155)
model = Sequential() # create model
model.add(Dense(40, input_dim=12, activation='tanh')) # hidden layer
model.add(Dense(20, input_dim=40, activation='tanh'))
model.add(Dense(1, activation='sigmoid')) # output layer

model.compile(loss= keras.losses.binary_crossentropy,
                  optimizer=keras.optimizers.adamax(),
                  metrics=['accuracy'])

tensorborad = TensorBoard(log_dir="logs/{}".format(time()))
history = model.fit(X_train, Y_train,batch_size=500,epochs=40,verbose=1,
           validation_data=(X_test, Y_test), callbacks=[tensorborad])

y_pred = model.predict_classes(X_test)

score = model.evaluate(X_test, Y_test, verbose=0)
print('Loss:', score[0])
print('Accuracy:', score[1])


def plot_hist(h, xsize=6, ysize=10):
    # Prepare plotting
    fig_size = plt.rcParams["figure.figsize"]
    plt.rcParams["figure.figsize"] = [xsize, ysize]
    fig, axes = plt.subplots(nrows=4, ncols=4, sharex=True)
    plt.subplot(212)
    plt.plot(h['loss'])
    plt.plot(h['val_loss'])
    plt.title('Training vs Validation Loss')
    plt.ylabel('Loss')
    plt.xlabel('Accuracy')
    plt.legend(['Train', 'Validation'], loc='upper left')

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs/

from __future__ import print_function
import keras
from keras.models import Sequential
from keras.layers import Dense
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from keras.callbacks import TensorBoard
from time import time


dataset = pd.read_csv('heart.csv',index_col=0)
dataset.astype(float)

# Normalize values to range [0:1]
dataset /= dataset.max()

y = dataset['target']
X = dataset.drop(['target'], axis = 1)

X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.28, random_state = 0)

np.random.seed(155)
model = Sequential() # create model
model.add(Dense(40, input_dim=12, activation='relu')) # hidden layer
model.add(Dense(20, input_dim=40, activation='relu'))
model.add(Dense(1, activation='sigmoid')) # output layer

model.compile(loss= keras.losses.binary_crossentropy,
                  optimizer=keras.optimizers.adamax(),
                  metrics=['accuracy'])

tensorborad = TensorBoard(log_dir="logs/{}".format(time()))
history = model.fit(X_train, Y_train,batch_size=500,epochs=40,verbose=1,
           validation_data=(X_test, Y_test), callbacks=[tensorborad])

y_pred = model.predict_classes(X_test)

score = model.evaluate(X_test, Y_test, verbose=0)
print('Loss:', score[0])
print('Accuracy:', score[1])


def plot_hist(h, xsize=6, ysize=10):
    # Prepare plotting
    fig_size = plt.rcParams["figure.figsize"]
    plt.rcParams["figure.figsize"] = [xsize, ysize]
    fig, axes = plt.subplots(nrows=4, ncols=4, sharex=True)
    plt.subplot(212)
    plt.plot(h['loss'])
    plt.plot(h['val_loss'])
    plt.title('Training vs Validation Loss')
    plt.ylabel('Loss')
    plt.xlabel('Accuracy')
    plt.legend(['Train', 'Validation'], loc='upper left')

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir logs/

from __future__ import print_function
import keras
from keras.models import Sequential
from keras.layers import Dense
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from keras.callbacks import TensorBoard
from time import time


dataset = pd.read_csv('heart.csv',index_col=0)
dataset.astype(float)

# Normalize values to range [0:1]
dataset /= dataset.max()

y = dataset['target']
X = dataset.drop(['target'], axis = 1)

X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.28, random_state = 0)

np.random.seed(155)
model = Sequential() # create model
model.add(Dense(40, input_dim=12, activation='relu')) # hidden layer
model.add(Dense(20, input_dim=40, activation='relu'))
model.add(Dense(1, activation='sigmoid')) # output layer

model.compile(loss= keras.losses.binary_crossentropy,
                  optimizer = keras.optimizers.SGD(),
                  metrics=['accuracy'])

tensorborad = TensorBoard(log_dir="logs/{}".format(time()))
history = model.fit(X_train, Y_train,batch_size=500,epochs=40,verbose=1,
           validation_data=(X_test, Y_test), callbacks=[tensorborad])

y_pred = model.predict_classes(X_test)

score = model.evaluate(X_test, Y_test, verbose=0)
print('Loss:', score[0])
print('Accuracy:', score[1])


def plot_hist(h, xsize=6, ysize=10):
    # Prepare plotting
    fig_size = plt.rcParams["figure.figsize"]
    plt.rcParams["figure.figsize"] = [xsize, ysize]
    fig, axes = plt.subplots(nrows=4, ncols=4, sharex=True)
    plt.subplot(212)
    plt.plot(h['loss'])
    plt.plot(h['val_loss'])
    plt.title('Training vs Validation Loss')
    plt.ylabel('Loss')
    plt.xlabel('Accuracy')
    plt.legend(['Train', 'Validation'], loc='upper left')

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard
# %tensorboard --logdir logs/